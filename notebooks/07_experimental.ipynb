{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78c10bb1",
   "metadata": {},
   "source": [
    "# Advanced Model Exploration\n",
    "\n",
    "This notebook explores additional advanced and experimental machine learning algorithms to further evaluate performance on the Kepler exoplanet dataset.\n",
    "\n",
    "The goal is to expand the model search space beyond standard baselines and ensembles, while maintaining consistent evaluation and reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4834cce6",
   "metadata": {},
   "source": [
    "## Section 1 - Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b04e266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c715dfda",
   "metadata": {},
   "source": [
    "## Load Feature-Engineered Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fa6964e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/processed/feature_engineered_data.csv\"\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "target_column = \"koi_disposition\"\n",
    "X = df.drop(columns=[target_column])\n",
    "y = df[target_column]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0873ec0",
   "metadata": {},
   "source": [
    "## Section 2 - Trainâ€“Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "776213b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b493da",
   "metadata": {},
   "source": [
    "## Section 3 - Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "221c9600",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = joblib.load(\"../models/standard_scaler.pkl\")\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c215a4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Results Directory Setup\n",
    "RESULTS_DIR = \"../results\"\n",
    "MODELS_DIR = \"../models\"\n",
    "\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639ce9b3",
   "metadata": {},
   "source": [
    "## Section 4 - Training, Evaluation, and Saving Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a31e0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_save(\n",
    "    model,\n",
    "    model_name,\n",
    "    X_tr,\n",
    "    X_te,\n",
    "    y_tr,\n",
    "    y_te\n",
    "):\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(f\"Training {model_name}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Train model\n",
    "    model.fit(X_tr, y_tr)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"Training completed in {elapsed:.2f} seconds\")\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_te)\n",
    "\n",
    "    # Create model-specific results directory\n",
    "    model_dir = os.path.join(\n",
    "        RESULTS_DIR,\n",
    "        model_name.replace(\" \", \"_\").lower()\n",
    "    )\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    # Classification report\n",
    "    report = classification_report(y_te, y_pred, output_dict=True)\n",
    "    with open(os.path.join(model_dir, \"classification_report.json\"), \"w\") as f:\n",
    "        json.dump(report, f, indent=4)\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_te, y_pred)\n",
    "    np.savetxt(\n",
    "        os.path.join(model_dir, \"confusion_matrix.csv\"),\n",
    "        cm,\n",
    "        delimiter=\",\",\n",
    "        fmt=\"%d\"\n",
    "    )\n",
    "\n",
    "    # ROC-AUC (if supported)\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_prob = model.predict_proba(X_te)\n",
    "        roc_auc = roc_auc_score(y_te, y_prob, multi_class=\"ovr\")\n",
    "        with open(os.path.join(model_dir, \"roc_auc.txt\"), \"w\") as f:\n",
    "            f.write(str(roc_auc))\n",
    "        print(\"ROC-AUC:\", roc_auc)\n",
    "    else:\n",
    "        print(\"ROC-AUC: N/A\")\n",
    "\n",
    "    # Save model\n",
    "    joblib.dump(\n",
    "        model,\n",
    "        os.path.join(\n",
    "            MODELS_DIR,\n",
    "            f\"{model_name.replace(' ', '_').lower()}.pkl\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print(f\"{model_name} saved successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fb4cd5",
   "metadata": {},
   "source": [
    "## Section 5 - AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbdbe8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training AdaBoost\n",
      "==================================================\n",
      "Training completed in 6.94 seconds\n",
      "ROC-AUC: 0.9557548845233241\n",
      "AdaBoost saved successfully\n"
     ]
    }
   ],
   "source": [
    "ada_model = AdaBoostClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=2),\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_evaluate_save(\n",
    "    ada_model,\n",
    "    \"AdaBoost\",\n",
    "    X_train,\n",
    "    X_test,\n",
    "    y_train,\n",
    "    y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0a481b",
   "metadata": {},
   "source": [
    "## Section 6 - Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43e41523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training Extra Trees\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 400 out of 400 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 400 out of 400 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed in 0.58 seconds\n",
      "ROC-AUC: 0.9792610301500869\n",
      "Extra Trees saved successfully\n"
     ]
    }
   ],
   "source": [
    "extra_trees_model = ExtraTreesClassifier(\n",
    "    n_estimators=400,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1 \n",
    ")\n",
    "\n",
    "train_evaluate_save(\n",
    "    extra_trees_model,\n",
    "    \"Extra Trees\",\n",
    "    X_train,\n",
    "    X_test,\n",
    "    y_train,\n",
    "    y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7646cd",
   "metadata": {},
   "source": [
    "## Section 7 - Ridge Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ed34823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training Ridge Classifier\n",
      "==================================================\n",
      "Training completed in 0.06 seconds\n",
      "ROC-AUC: N/A\n",
      "Ridge Classifier saved successfully\n"
     ]
    }
   ],
   "source": [
    "ridge_model = RidgeClassifier(class_weight=\"balanced\")\n",
    "\n",
    "train_evaluate_save(\n",
    "    ridge_model,\n",
    "    \"Ridge Classifier\",\n",
    "    X_train_scaled,\n",
    "    X_test_scaled,\n",
    "    y_train,\n",
    "    y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a171bb2",
   "metadata": {},
   "source": [
    "## Section 8 - Gaussian Process Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f47935c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training Gaussian Process\n",
      "==================================================\n",
      "Training completed in 1993.08 seconds\n",
      "ROC-AUC: 0.9716933289647193\n",
      "Gaussian Process saved successfully\n"
     ]
    }
   ],
   "source": [
    "gpc_model = GaussianProcessClassifier(\n",
    "    kernel=RBF(length_scale=1.0),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_evaluate_save(\n",
    "    gpc_model,\n",
    "    \"Gaussian Process\",\n",
    "    X_train_scaled,\n",
    "    X_test_scaled,\n",
    "    y_train,\n",
    "    y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a006d8d",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- Multiple advanced models were trained with visible progress\n",
    "- Both linear and non-linear algorithms were explored\n",
    "- All models and evaluation outputs were saved\n",
    "- This notebook further expands the model search space\n",
    "\n",
    "The project is now ready for final aggregation and model selection."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
